{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import os\n",
    "\n",
    "from torchvision import utils\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torchsummary import summary\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_hairLoss = pd.read_csv('./Data/train_df', index_col=0)\n",
    "test_data_hairLoss = pd.read_csv('./Data/test_df', index_col=0)\n",
    "\n",
    "# 이미지 파일 경로를 포함한 DataFrame 생성\n",
    "train_path = train_data_hairLoss[['image_path']]\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # 이미지 크기 조정\n",
    "    transforms.ToTensor(),  # 이미지를 텐서로 변환\n",
    "    transforms.Normalize(mean=[0.25, 0.25, 0.25], std=[0.1, 0.1, 0.1])  # 이미지 정규화\n",
    "])\n",
    "\n",
    "tensor_list_train = []\n",
    "tensor_list_test = []\n",
    "for image_path in train_path['image_path']:\n",
    "    image = Image.open(image_path)\n",
    "    tensor = transform(image)\n",
    "    tensor_list_train.append(tensor)\n",
    "\n",
    "image_tensors_train = torch.stack(tensor_list_train) #train데이터\n",
    "    \n",
    "# 이미지 파일 경로를 포함한 DataFrame 생성\n",
    "test_path = test_data_hairLoss[['image_path']]\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # 이미지 크기 조정\n",
    "    transforms.ToTensor(),  # 이미지를 텐서로 변환\n",
    "    transforms.Normalize(mean=[0.25, 0.25, 0.25], std=[0.1, 0.1, 0.1])  # 이미지 정규화\n",
    "])\n",
    "\n",
    "\n",
    "for image_path in test_path['image_path']:\n",
    "    image = Image.open(image_path)\n",
    "    tensor = transform(image)\n",
    "    tensor_list_test.append(tensor)\n",
    "\n",
    "image_tensors_test = torch.stack(tensor_list_test) #test데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = image_tensors_train\n",
    "y_train = train_data_hairLoss['탈모'].values\n",
    "X_test = image_tensors_test\n",
    "y_test = test_data_hairLoss['탈모'].values\n",
    "\n",
    "# 데이터셋 생성\n",
    "train_dataset = TensorDataset(X_train, torch.LongTensor(y_train))\n",
    "test_dataset = TensorDataset(X_test, torch.LongTensor(y_test))\n",
    "\n",
    "batch_size = 16  # 배치 크기 설정\n",
    "\n",
    "# 데이터 로더 생성\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DenseNet BottleNeck\n",
    "\n",
    "class BottleNeck(nn.Module):\n",
    "    def __init__(self, in_channels, growth_rate):\n",
    "        super().__init__()\n",
    "        inner_channels = 4 * growth_rate\n",
    "\n",
    "        self.residual = nn.Sequential(\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels, inner_channels, 1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(inner_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(inner_channels, growth_rate, 3, stride=1, padding=1, bias=False)\n",
    "        )\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat([self.shortcut(x), self.residual(x)], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transition Block: 피쳐맵 크기와 채널 수 감소\n",
    "\n",
    "class Transition(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.down_sample = nn.Sequential(\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels, out_channels, 1, stride=1, padding=0, bias=False),\n",
    "            nn.AvgPool2d(2, stride=2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.down_sample(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DenseNet\n",
    "\n",
    "class DenseNet(nn.Module):\n",
    "    def __init__(self, nblocks, growth_rate=12, reduction=0.5, num_classes=4, init_weights=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.growth_rate = growth_rate\n",
    "        inner_channels = 2 * growth_rate # output channels of conv1 before entering Dense Block\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, inner_channels, 7, stride=2, padding=3),\n",
    "            nn.MaxPool2d(3, 2, padding=1)\n",
    "        )\n",
    "\n",
    "        self.features = nn.Sequential()\n",
    "\n",
    "        for i in range(len(nblocks)-1):\n",
    "            self.features.add_module('dense_block_{}'.format(i), self._make_dense_block(nblocks[i], inner_channels))\n",
    "            inner_channels += growth_rate * nblocks[i]\n",
    "            out_channels = int(reduction * inner_channels)\n",
    "            self.features.add_module('transition_layer_{}'.format(i), Transition(inner_channels, out_channels))\n",
    "            inner_channels = out_channels \n",
    "        \n",
    "        self.features.add_module('dense_block_{}'.format(len(nblocks)-1), self._make_dense_block(nblocks[len(nblocks)-1], inner_channels))\n",
    "        inner_channels += growth_rate * nblocks[len(nblocks)-1]\n",
    "        self.features.add_module('bn', nn.BatchNorm2d(inner_channels))\n",
    "        self.features.add_module('relu', nn.ReLU())\n",
    "\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.linear = nn.Linear(inner_channels, num_classes)\n",
    "\n",
    "        # weight initialization\n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.features(x)\n",
    "        x = self.avg_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "    def _make_dense_block(self, nblock, inner_channels):\n",
    "        dense_block = nn.Sequential()\n",
    "        for i in range(nblock):\n",
    "            dense_block.add_module('bottle_neck_layer_{}'.format(i), BottleNeck(inner_channels, self.growth_rate))\n",
    "            inner_channels += self.growth_rate\n",
    "        return dense_block\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "def DenseNet_121():\n",
    "    return DenseNet([6, 12, 24, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = DenseNet_121()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss function, optimizer, lr_scheduler\n",
    "loss_func = nn.CrossEntropyLoss(reduction='sum')\n",
    "opt = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "lr_scheduler = ReduceLROnPlateau(opt, mode='min', factor=0.1, patience=8)\n",
    "\n",
    "\n",
    "# get current lr\n",
    "def get_lr(opt):\n",
    "    for param_group in opt.param_groups:\n",
    "        return param_group['lr']\n",
    "\n",
    "\n",
    "# calculate the metric per mini-batch\n",
    "def metric_batch(output, target):\n",
    "    pred = output.argmax(1, keepdim=True)\n",
    "    corrects = pred.eq(target.view_as(pred)).sum().item()\n",
    "    return corrects\n",
    "\n",
    "\n",
    "# calculate the loss per mini-batch\n",
    "def loss_batch(loss_func, output, target, opt=None):\n",
    "    loss_b = loss_func(output, target)\n",
    "    metric_b = metric_batch(output, target)\n",
    "\n",
    "    if opt is not None:\n",
    "        opt.zero_grad()\n",
    "        loss_b.backward()\n",
    "        opt.step()\n",
    "    \n",
    "    return loss_b.item(), metric_b\n",
    "\n",
    "\n",
    "# calculate the loss per epochs\n",
    "def loss_epoch(model, loss_func, dataset_dl, sanity_check=False, opt=None):\n",
    "    running_loss = 0.0\n",
    "    running_metric = 0.0\n",
    "    len_data = len(dataset_dl.dataset)\n",
    "\n",
    "    for xb, yb in dataset_dl:\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "        output = model(xb)\n",
    "\n",
    "        loss_b, metric_b = loss_batch(loss_func, output, yb, opt)\n",
    "\n",
    "        running_loss += loss_b\n",
    "        \n",
    "        if metric_b is not None:\n",
    "            running_metric += metric_b\n",
    "\n",
    "        if sanity_check is True:\n",
    "            break\n",
    "\n",
    "    loss = running_loss / len_data\n",
    "    metric = running_metric / len_data\n",
    "    return loss, metric\n",
    "\n",
    "\n",
    "# function to start training\n",
    "def train_val(model, params):\n",
    "    num_epochs=params['num_epochs']\n",
    "    loss_func=params['loss_func']\n",
    "    opt=params['optimizer']\n",
    "    train_dl=params['train_dl']\n",
    "    val_dl=params['val_dl']\n",
    "    sanity_check=params['sanity_check']\n",
    "    lr_scheduler=params['lr_scheduler']\n",
    "    #path2weights=params['path2weights']\n",
    "\n",
    "    loss_history = {'train': [], 'val': []}\n",
    "    metric_history = {'train': [], 'val': []}\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        current_lr = get_lr(opt)\n",
    "        print('Epoch {}/{}, current lr= {}'.format(epoch+1, num_epochs, current_lr))\n",
    "\n",
    "        model.train()\n",
    "        train_loss, train_metric = loss_epoch(model, loss_func, train_dl, sanity_check, opt)\n",
    "        loss_history['train'].append(train_loss)\n",
    "        metric_history['train'].append(train_metric)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss, val_metric = loss_epoch(model, loss_func, val_dl, sanity_check)\n",
    "        loss_history['val'].append(val_loss)\n",
    "        metric_history['val'].append(val_metric)\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            #torch.save(model.state_dict(), path2weights)\n",
    "            print('Copied best model weights!')\n",
    "\n",
    "        lr_scheduler.step(val_loss)\n",
    "        if current_lr != get_lr(opt):\n",
    "            print('Loading best model weights!')\n",
    "            model.load_state_dict(best_model_wts)\n",
    "\n",
    "        print('train loss: %.6f, val loss: %.6f, accuracy: %.2f, time: %.4f min' %(train_loss, val_loss, 100*val_metric, (time.time()-start_time)/60))\n",
    "        print('-'*10)\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, loss_history, metric_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the training parameters\n",
    "params_train = {\n",
    "    'num_epochs':30,\n",
    "    'optimizer':opt,\n",
    "    'loss_func':loss_func,\n",
    "    'train_dl':train_loader,\n",
    "    'val_dl':test_loader,\n",
    "    'sanity_check':False,\n",
    "    'lr_scheduler':lr_scheduler\n",
    "    #'path2weights':'./models/weights.pt',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, current lr= 0.01\n",
      "Copied best model weights!\n",
      "train loss: 0.690747, val loss: 0.654698, accuracy: 73.70, time: 0.8086 min\n",
      "----------\n",
      "Epoch 2/10, current lr= 0.01\n",
      "Copied best model weights!\n",
      "train loss: 0.647879, val loss: 0.640843, accuracy: 75.38, time: 1.6141 min\n",
      "----------\n",
      "Epoch 3/10, current lr= 0.01\n",
      "train loss: 0.643436, val loss: 0.660212, accuracy: 72.33, time: 2.4196 min\n",
      "----------\n",
      "Epoch 4/10, current lr= 0.01\n",
      "Copied best model weights!\n",
      "train loss: 0.637789, val loss: 0.620426, accuracy: 75.51, time: 3.2250 min\n",
      "----------\n",
      "Epoch 5/10, current lr= 0.01\n",
      "train loss: 0.632867, val loss: 0.650792, accuracy: 74.77, time: 4.0302 min\n",
      "----------\n",
      "Epoch 6/10, current lr= 0.01\n",
      "train loss: 0.625329, val loss: 0.709284, accuracy: 72.77, time: 4.8435 min\n",
      "----------\n",
      "Epoch 7/10, current lr= 0.01\n",
      "Copied best model weights!\n",
      "train loss: 0.625950, val loss: 0.608041, accuracy: 75.25, time: 5.6518 min\n",
      "----------\n",
      "Epoch 8/10, current lr= 0.01\n",
      "train loss: 0.618588, val loss: 0.623315, accuracy: 75.00, time: 6.4595 min\n",
      "----------\n",
      "Epoch 9/10, current lr= 0.01\n",
      "train loss: 0.617546, val loss: 0.638121, accuracy: 73.03, time: 7.2635 min\n",
      "----------\n",
      "Epoch 10/10, current lr= 0.01\n",
      "train loss: 0.614576, val loss: 0.627388, accuracy: 74.91, time: 8.0658 min\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "model, loss_hist, metric_hist = train_val(model, params_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, './Model/model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_Study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1c82d1a80ee0d4ff8d4114458f1a4bf9de876e6d83c0940c915b29fd45e0fe5f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
